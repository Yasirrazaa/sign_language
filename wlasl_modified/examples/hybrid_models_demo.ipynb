{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Transformer Models for Sign Language Recognition\n",
    "\n",
    "This notebook demonstrates the usage of memory-efficient hybrid transformer models:\n",
    "1. CNN-Transformer\n",
    "2. TimeSformer\n",
    "\n",
    "We'll compare their performance, memory usage, and training characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "from src.models.hybrid_transformers import create_model\n",
    "from src.training.hybrid_trainers import create_trainer\n",
    "from configs.hybrid_transformer_config import get_config, print_memory_recommendations\n",
    "\n",
    "# Enable notebook-wide memory tracking\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Memory Usage Analysis\n",
    "\n",
    "First, let's analyze memory usage patterns of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def profile_model_memory(model_name: str, batch_size: int = 8):\n",
    "    \"\"\"Profile model memory usage.\"\"\"\n",
    "    config = get_config(model_name)\n",
    "    model = create_model(\n",
    "        model_name=model_name,\n",
    "        num_classes=26,\n",
    "        num_frames=30\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    # Create dummy input\n",
    "    x = torch.randn(batch_size, 30, 3, 224, 224)\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    \n",
    "    # Profile forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "    \n",
    "    memory_stats = {\n",
    "        'ram_used': psutil.Process().memory_info().rss / 1024**3,\n",
    "        'gpu_allocated': torch.cuda.memory_allocated() / 1024**3 if torch.cuda.is_available() else 0,\n",
    "        'gpu_reserved': torch.cuda.memory_reserved() / 1024**3 if torch.cuda.is_available() else 0\n",
    "    }\n",
    "    \n",
    "    return memory_stats\n",
    "\n",
    "# Profile both models\n",
    "models = ['cnn_transformer', 'timesformer']\n",
    "batch_sizes = [1, 2, 4, 8, 16]\n",
    "memory_data = []\n",
    "\n",
    "for model_name in models:\n",
    "    for bs in batch_sizes:\n",
    "        stats = profile_model_memory(model_name, bs)\n",
    "        stats.update({'model': model_name, 'batch_size': bs})\n",
    "        memory_data.append(stats)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Plot results\n",
    "df = pd.DataFrame(memory_data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data=df, x='batch_size', y='gpu_allocated', hue='model')\n",
    "plt.title('GPU Memory Usage')\n",
    "plt.ylabel('Memory (GB)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(data=df, x='batch_size', y='ram_used', hue='model')\n",
    "plt.title('RAM Usage')\n",
    "plt.ylabel('Memory (GB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Performance Comparison\n",
    "\n",
    "Let's compare training performance of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_model(model_name: str, num_epochs: int = 5):\n",
    "    \"\"\"Train model and track metrics.\"\"\"\n",
    "    config = get_config(model_name)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(\n",
    "        model_name=model_name,\n",
    "        num_classes=26,\n",
    "        num_frames=30\n",
    "    )\n",
    "    \n",
    "    # Create dummy dataset\n",
    "    class DummyDataset(torch.utils.data.Dataset):\n",
    "        def __len__(self):\n",
    "            return 100\n",
    "        def __getitem__(self, idx):\n",
    "            x = torch.randn(30, 3, 224, 224)\n",
    "            y = torch.randint(0, 26, (1,))[0]\n",
    "            return x, y\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        DummyDataset(),\n",
    "        batch_size=config['trainer'].batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        DummyDataset(),\n",
    "        batch_size=config['trainer'].batch_size\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = create_trainer(\n",
    "        model_name=model_name,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=torch.nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.Adam(model.parameters()),\n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "        config=config['trainer'],\n",
    "        checkpoint_dir=Path('checkpoints') / model_name\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'memory_usage': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = trainer.train_epoch()\n",
    "        val_metrics = trainer.validate()\n",
    "        \n",
    "        history['train_loss'].append(train_metrics['loss'])\n",
    "        history['val_loss'].append(val_metrics['val_loss'])\n",
    "        history['val_accuracy'].append(val_metrics['val_accuracy'])\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            history['memory_usage'].append(\n",
    "                torch.cuda.memory_allocated() / 1024**3\n",
    "            )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train both models\n",
    "histories = {}\n",
    "for model_name in models:\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    histories[model_name] = train_model(model_name)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for model_name in models:\n",
    "    history = histories[model_name]\n",
    "    axes[0].plot(history['train_loss'], label=f'{model_name} train')\n",
    "    axes[0].plot(history['val_loss'], label=f'{model_name} val')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(history['val_accuracy'], label=model_name)\n",
    "    axes[1].set_title('Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    if 'memory_usage' in history:\n",
    "        axes[2].plot(history['memory_usage'], label=model_name)\n",
    "        axes[2].set_title('GPU Memory Usage (GB)')\n",
    "        axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Features and Attention Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_attention(model_name: str, sample_video: torch.Tensor):\n",
    "    \"\"\"Visualize model attention patterns.\"\"\"\n",
    "    model = create_model(\n",
    "        model_name=model_name,\n",
    "        num_classes=26,\n",
    "        num_frames=30\n",
    "    ).eval()\n",
    "    \n",
    "    # Get attention weights\n",
    "    if model_name == 'cnn_transformer':\n",
    "        # Get transformer attention from last layer\n",
    "        attention = model.blocks[-1].attn.get_attention_weights(sample_video)\n",
    "    else:\n",
    "        # Get space-time attention\n",
    "        attention = model.blocks[-1].get_attention_weights(sample_video)\n",
    "    \n",
    "    # Plot attention patterns\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(attention[0].mean(0).cpu().detach())\n",
    "    plt.title(f'{model_name} Attention Pattern')\n",
    "    plt.xlabel('Key frames')\n",
    "    plt.ylabel('Query frames')\n",
    "    plt.show()\n",
    "\n",
    "# Create sample video\n",
    "sample_video = torch.randn(1, 30, 3, 224, 224)\n",
    "\n",
    "# Visualize attention for both models\n",
    "for model_name in models:\n",
    "    visualize_attention(model_name, sample_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory Efficiency Tips\n",
    "\n",
    "Here are some key recommendations for memory-efficient training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print_memory_recommendations()\n",
    "\n",
    "# Additional tips\n",
    "tips = [\n",
    "    \"1. Use appropriate batch size and gradient accumulation:\",\n",
    "    \"   - CNN-Transformer: batch_size=8, grad_accum=4\",\n",
    "    \"   - TimeSformer: batch_size=4, grad_accum=8\",\n",
    "    \"\\n2. Enable memory optimizations:\",\n",
    "    \"   model_config.use_checkpoint = True\",\n",
    "    \"   trainer_config.mixed_precision = True\",\n",
    "    \"\\n3. Monitor memory usage:\",\n",
    "    \"   trainer.memory_tracker.check_memory()\"\n",
    "]\n",
    "\n",
    "print(\"\\nImplementation Tips:\")\n",
    "print(\"\\n\".join(tips))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}