{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Model Comparison for Sign Language Recognition\n",
    "\n",
    "This notebook compares all implemented models:\n",
    "1. Original I3D Model (WLASL baseline)\n",
    "2. Memory-Efficient Models\n",
    "3. Hybrid Transformer Models\n",
    "\n",
    "We'll evaluate:\n",
    "- Model performance\n",
    "- Memory efficiency\n",
    "- Training speed\n",
    "- Cross-validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "# Import original I3D model\n",
    "from WLASL.code.I3D.models.pytorch_i3d import InceptionI3d\n",
    "\n",
    "# Import memory-efficient models\n",
    "from wlasl_modified.src.models.efficient_sign_net import EfficientSignNet\n",
    "\n",
    "# Import hybrid models\n",
    "from wlasl_modified.src.models.hybrid_transformers import CNNTransformer, TimeSformer\n",
    "\n",
    "# Import data processing\n",
    "from wlasl_modified.src.data.preprocessing import MemoryEfficientPreprocessor\n",
    "from wlasl_modified.src.data.loader import create_data_loaders\n",
    "\n",
    "# Import training utilities\n",
    "from wlasl_modified.src.training.hybrid_trainers import create_trainer\n",
    "from wlasl_modified.src.training.cross_validate import CrossValidationTrainer\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure data paths\n",
    "DATA_DIR = Path('data')\n",
    "PROCESSED_DIR = Path('processed')\n",
    "\n",
    "def prepare_dataset(data_dir: Path, processed_dir: Path):\n",
    "    \"\"\"Prepare dataset with memory-efficient preprocessing.\"\"\"\n",
    "    preprocessor = MemoryEfficientPreprocessor(\n",
    "        output_dir=processed_dir / 'frames',\n",
    "        frame_size=(224, 224),\n",
    "        target_fps=25,\n",
    "        chunk_size=32\n",
    "    )\n",
    "    \n",
    "    # Process videos\n",
    "    video_paths = list(data_dir.glob('**/*.mp4'))\n",
    "    logger.info(f\"Found {len(video_paths)} videos\")\n",
    "    \n",
    "    results = []\n",
    "    for video_path in tqdm(video_paths, desc=\"Processing videos\"):\n",
    "        try:\n",
    "            result = preprocessor.preprocess_video(video_path)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {video_path}: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Prepare dataset if not already processed\n",
    "if not (PROCESSED_DIR / 'frames').exists():\n",
    "    preprocessing_results = prepare_dataset(DATA_DIR, PROCESSED_DIR)\n",
    "else:\n",
    "    logger.info(\"Using previously processed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_dataset(processed_dir: Path):\n",
    "    \"\"\"Analyze processed dataset statistics.\"\"\"\n",
    "    frame_dirs = list((processed_dir / 'frames').glob('*'))\n",
    "    \n",
    "    stats = {\n",
    "        'num_samples': len(frame_dirs),\n",
    "        'frames_per_video': [],\n",
    "        'video_sizes': []\n",
    "    }\n",
    "    \n",
    "    for frame_dir in frame_dirs:\n",
    "        frames = list(frame_dir.glob('*.jpg'))\n",
    "        stats['frames_per_video'].append(len(frames))\n",
    "        \n",
    "        # Calculate video size\n",
    "        size = sum(f.stat().st_size for f in frames) / 1024**2  # MB\n",
    "        stats['video_sizes'].append(size)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze dataset\n",
    "dataset_stats = analyze_dataset(PROCESSED_DIR)\n",
    "\n",
    "# Plot statistics\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Frames per video distribution\n",
    "sns.histplot(dataset_stats['frames_per_video'], ax=ax1)\n",
    "ax1.set_title('Frames per Video Distribution')\n",
    "ax1.set_xlabel('Number of Frames')\n",
    "\n",
    "# Video sizes distribution\n",
    "sns.histplot(dataset_stats['video_sizes'], ax=ax2)\n",
    "ax2.set_title('Video Sizes Distribution')\n",
    "ax2.set_xlabel('Size (MB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Creation and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_models(num_classes: int):\n",
    "    \"\"\"Create all model variants.\"\"\"\n",
    "    models = {\n",
    "        'i3d': InceptionI3d(\n",
    "            num_classes=num_classes,\n",
    "            in_channels=3\n",
    "        ),\n",
    "        'efficient': EfficientSignNet(\n",
    "            num_classes=num_classes,\n",
    "            in_channels=3\n",
    "        ),\n",
    "        'cnn_transformer': CNNTransformer(\n",
    "            num_classes=num_classes,\n",
    "            num_frames=30\n",
    "        ),\n",
    "        'timesformer': TimeSformer(\n",
    "            num_classes=num_classes,\n",
    "            num_frames=30\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Create models\n",
    "NUM_CLASSES = 26  # Adjust based on your dataset\n",
    "models = create_models(NUM_CLASSES)\n",
    "\n",
    "# Print model summaries\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name.upper()} Model Summary:\")\n",
    "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_and_evaluate(models: dict, data_loaders: dict, num_epochs: int = 20):\n",
    "    \"\"\"Train and evaluate all models with cross-validation.\"\"\"\n",
    "    results = {}\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        logger.info(f\"\\nTraining {name}...\")\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = CrossValidationTrainer(\n",
    "            model=model,\n",
    "            train_loader=data_loaders['train'],\n",
    "            val_loader=data_loaders['val'],\n",
    "            device=device,\n",
    "            num_folds=7\n",
    "        )\n",
    "        \n",
    "        # Train with cross-validation\n",
    "        cv_results = trainer.train(num_epochs)\n",
    "        results[name] = cv_results\n",
    "        \n",
    "        # Clear memory\n",
    "        del model, trainer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create data loaders\n",
    "data_loaders = create_data_loaders(\n",
    "    processed_dir=PROCESSED_DIR,\n",
    "    batch_size=8,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Train all models\n",
    "cv_results = train_and_evaluate(models, data_loaders)\n",
    "\n",
    "# Plot cross-validation results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for name, result in cv_results.items():\n",
    "    ax1.plot(result['val_accuracy'], label=name)\n",
    "    ax2.plot(result['val_loss'], label=name)\n",
    "\n",
    "ax1.set_title('Validation Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title('Validation Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Memory Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def profile_memory_usage(models: dict, sample_batch: torch.Tensor):\n",
    "    \"\"\"Profile memory usage for all models.\"\"\"\n",
    "    memory_stats = {}\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model = model.to(device)\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            _ = model(sample_batch.to(device))\n",
    "        \n",
    "        memory_stats[name] = {\n",
    "            'gpu_allocated': torch.cuda.memory_allocated() / 1024**2,\n",
    "            'gpu_reserved': torch.cuda.memory_reserved() / 1024**2\n",
    "        }\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return memory_stats\n",
    "\n",
    "# Create sample batch\n",
    "sample_batch = torch.randn(8, 30, 3, 224, 224)\n",
    "\n",
    "# Profile memory usage\n",
    "memory_stats = profile_memory_usage(models, sample_batch)\n",
    "\n",
    "# Plot memory usage\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(memory_stats))\n",
    "width = 0.35\n",
    "\n",
    "allocated = [stats['gpu_allocated'] for stats in memory_stats.values()]\n",
    "reserved = [stats['gpu_reserved'] for stats in memory_stats.values()]\n",
    "\n",
    "ax.bar(x - width/2, allocated, width, label='Allocated')\n",
    "ax.bar(x + width/2, reserved, width, label='Reserved')\n",
    "\n",
    "ax.set_ylabel('Memory (MB)')\n",
    "ax.set_title('GPU Memory Usage by Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(memory_stats.keys())\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compile_metrics(cv_results: dict):\n",
    "    \"\"\"Compile performance metrics for all models.\"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    for name, result in cv_results.items():\n",
    "        metrics.append({\n",
    "            'model': name,\n",
    "            'accuracy': np.mean(result['val_accuracy']),\n",
    "            'accuracy_std': np.std(result['val_accuracy']),\n",
    "            'training_time': result.get('training_time', 0),\n",
    "            'memory_usage': memory_stats[name]['gpu_allocated']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Compile and display metrics\n",
    "metrics_df = compile_metrics(cv_results)\n",
    "display(metrics_df)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Accuracy comparison\n",
    "sns.barplot(data=metrics_df, x='model', y='accuracy', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Model Accuracy')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Training time comparison\n",
    "sns.barplot(data=metrics_df, x='model', y='training_time', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Training Time (s)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Memory usage comparison\n",
    "sns.barplot(data=metrics_df, x='model', y='memory_usage', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Memory Usage (MB)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Accuracy vs Memory trade-off\n",
    "sns.scatterplot(data=metrics_df, x='memory_usage', y='accuracy', ax=axes[1, 1])\n",
    "for i, row in metrics_df.iterrows():\n",
    "    axes[1, 1].annotate(row['model'], (row['memory_usage'], row['accuracy']))\n",
    "axes[1, 1].set_title('Accuracy vs Memory Trade-off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Recommendations\n",
    "\n",
    "Based on the comparison above:\n",
    "\n",
    "1. Model Performance:\n",
    "   - Best accuracy: [Model name]\n",
    "   - Most memory efficient: [Model name]\n",
    "   - Best accuracy/memory trade-off: [Model name]\n",
    "\n",
    "2. Recommendations:\n",
    "   - For high accuracy: Use [Model name]\n",
    "   - For limited resources: Use [Model name]\n",
    "   - For balanced performance: Use [Model name]\n",
    "\n",
    "3. Memory Optimization Tips:\n",
    "   - Use gradient checkpointing for large models\n",
    "   - Enable mixed precision training\n",
    "   - Adjust batch size based on available memory\n",
    "   - Use appropriate model for your hardware constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}