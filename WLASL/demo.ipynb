{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced WLASL Framework Demo\n",
    "\n",
    "This notebook demonstrates the complete pipeline of the enhanced WLASL framework, including:\n",
    "1. Data Loading and Preprocessing\n",
    "2. Data Analysis\n",
    "3. Model Training\n",
    "4. Cross-Validation\n",
    "5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path().absolute()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from configs.base_config import *\n",
    "from src.preprocessing.video_processor import VideoProcessor, BatchVideoProcessor\n",
    "from src.data.data_loader import SignLanguageDataset, create_data_loaders\n",
    "from src.training.trainer import Trainer\n",
    "from src.training.cross_validate import CrossValidator\n",
    "\n",
    "# Enable interactive plots\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "First, let's load and preprocess some sample videos using our memory-efficient processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize video processor\n",
    "video_processor = VideoProcessor(\n",
    "    frame_size=DATA_CONFIG['frame_size'],\n",
    "    num_frames=DATA_CONFIG['num_frames'],\n",
    "    fps=DATA_CONFIG['fps']\n",
    ")\n",
    "\n",
    "# Process a batch of videos\n",
    "sample_video_dir = DATA_DIR / 'raw_videos'\n",
    "video_paths = list(sample_video_dir.glob('*.mp4'))\n",
    "\n",
    "print(f\"Found {len(video_paths)} videos to process\")\n",
    "\n",
    "batch_processor = BatchVideoProcessor(video_processor)\n",
    "batch_processor.process_batch(video_paths[:5])  # Process first 5 videos as example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Processed Frames\n",
    "\n",
    "Let's look at some processed frames to verify our preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_video_frames(video_path, num_frames=5):\n",
    "    \"\"\"Plot sample frames from a processed video.\"\"\"\n",
    "    frames = video_processor.process_video(video_path)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_frames, figsize=(15, 3))\n",
    "    step = len(frames) // num_frames\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(frames[i * step])\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Frame {i * step}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize frames from first video\n",
    "plot_video_frames(video_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis\n",
    "\n",
    "Now let's analyze our dataset to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load dataset info\n",
    "import json\n",
    "with open(DATA_DIR / 'data_info.json', 'r') as f:\n",
    "    data_info = json.load(f)\n",
    "\n",
    "# Analyze class distribution\n",
    "class_counts = {}\n",
    "signer_counts = {}\n",
    "\n",
    "for item in data_info:\n",
    "    class_counts[item['label']] = class_counts.get(item['label'], 0) + 1\n",
    "    signer_counts[item['signer_id']] = signer_counts.get(item['signer_id'], 0) + 1\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(class_counts)), sorted(class_counts.values(), reverse=True))\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n",
    "\n",
    "# Plot signer distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(signer_counts)), sorted(signer_counts.values(), reverse=True))\n",
    "plt.title('Signer Distribution')\n",
    "plt.xlabel('Signer ID')\n",
    "plt.ylabel('Number of Videos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Let's train both I3D and TGCN models on our processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create data loaders\n",
    "dataloaders = create_data_loaders(data_info)\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate_model(model_name):\n",
    "    # Setup model\n",
    "    if model_name == 'i3d':\n",
    "        from code.I3D.pytorch_i3d import InceptionI3d\n",
    "        model = InceptionI3d(**I3D_CONFIG)\n",
    "    else:\n",
    "        from code.TGCN.tgcn_model import TGCN\n",
    "        model = TGCN(**TGCN_CONFIG)\n",
    "    \n",
    "    # Setup training\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=TRAIN_CONFIG['learning_rate'],\n",
    "        weight_decay=TRAIN_CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=TRAIN_CONFIG['reduce_lr_factor'],\n",
    "        patience=TRAIN_CONFIG['reduce_lr_patience']\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=dataloaders['train'],\n",
    "        val_loader=dataloaders['val'],\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = trainer.train()\n",
    "    return history\n",
    "\n",
    "# Train I3D model\n",
    "print(\"Training I3D model...\")\n",
    "i3d_history = train_and_evaluate_model('i3d')\n",
    "\n",
    "# Train TGCN model\n",
    "print(\"\\nTraining TGCN model...\")\n",
    "tgcn_history = train_and_evaluate_model('tgcn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation\n",
    "\n",
    "Now let's perform cross-validation to get a better estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_cross_validation(model_name):\n",
    "    if model_name == 'i3d':\n",
    "        from code.I3D.pytorch_i3d import InceptionI3d as ModelClass\n",
    "        model_params = I3D_CONFIG\n",
    "    else:\n",
    "        from code.TGCN.tgcn_model import TGCN as ModelClass\n",
    "        model_params = TGCN_CONFIG\n",
    "    \n",
    "    validator = CrossValidator(\n",
    "        model_class=ModelClass,\n",
    "        model_params=model_params,\n",
    "        data_info=data_info,\n",
    "        num_folds=TRAIN_CONFIG['num_folds']\n",
    "    )\n",
    "    \n",
    "    results = validator.run()\n",
    "    return results\n",
    "\n",
    "# Run cross-validation for both models\n",
    "print(\"Running cross-validation for I3D...\")\n",
    "i3d_cv_results = run_cross_validation('i3d')\n",
    "\n",
    "print(\"\\nRunning cross-validation for TGCN...\")\n",
    "tgcn_cv_results = run_cross_validation('tgcn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization\n",
    "\n",
    "Let's visualize the results of our training and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_training_curves(history, title):\n",
    "    \"\"\"Plot training and validation curves.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(history['train_loss'], label='Train')\n",
    "    ax1.plot(history['val_loss'], label='Validation')\n",
    "    ax1.set_title(f'{title} - Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Accuracy curves\n",
    "    ax2.plot(history['train_acc'], label='Train')\n",
    "    ax2.plot(history['val_acc'], label='Validation')\n",
    "    ax2.set_title(f'{title} - Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_curves(i3d_history, 'I3D Model')\n",
    "plot_training_curves(tgcn_history, 'TGCN Model')\n",
    "\n",
    "# Print cross-validation results\n",
    "def print_cv_results(results, model_name):\n",
    "    print(f\"\\n{model_name} Cross-Validation Results:\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric, values in results['aggregate_metrics'].items():\n",
    "        print(f\"{metric}: {values['mean']:.2f} Â± {values['std']:.2f}\")\n",
    "\n",
    "print_cv_results(i3d_cv_results, 'I3D')\n",
    "print_cv_results(tgcn_cv_results, 'TGCN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Analysis\n",
    "\n",
    "Finally, let's compare the performance of both models and analyze their strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compare_models(i3d_results, tgcn_results):\n",
    "    \"\"\"Compare performance metrics between models.\"\"\"\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    model_names = ['I3D', 'TGCN']\n",
    "    metric_data = {\n",
    "        metric: [i3d_results['aggregate_metrics'][metric]['mean'],\n",
    "                tgcn_results['aggregate_metrics'][metric]['mean']]\n",
    "        for metric in metrics\n",
    "    }\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.15\n",
    "    multiplier = 0\n",
    "    \n",
    "    for attribute, measurement in metric_data.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "        multiplier += 1\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Performance Comparison')\n",
    "    ax.set_xticks(x + width * 2)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Compare model performances\n",
    "compare_models(i3d_cv_results, tgcn_cv_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}